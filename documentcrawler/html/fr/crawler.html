<h1>crawler(1) - Moteur d&rsquo;exploration permettant de déplacer des données du point A au point B</h1><h2>SYNOPSIS</h2><p>Syntaxe : crawler [ crawl | testit | restart | resume | refresh | summary ][ options ]</p><h2>DESCRIPTION</h2><p>Data Crawler permet d&rsquo;explorer divers référentiels de données, tels que des systèmes de gestion de contenu et des systèmes de fichiers,<br/>puis d&rsquo;envoyer les documents résultants à un service distant. </p><h2>OPTIONS GENERALES</h2>
<pre><code>--version
    Affiche la version du programme
--help
    Affiche le texte de cette syntaxe
</code></pre><h2>COMMANDES</h2><h3>crawl [ options ]</h3><p>Exécute une exploration avec la configuration en cours. </p>
<pre><code>-c &lt;valeur&gt; | --config &lt;valeur&gt;  # Indique le fichier de configuration à utiliser. Le fichier par défaut est &quot;config/crawler.conf&quot;.
--pii-checking &lt;valeur&gt;         # Active/Désactive la vérification du PII
</code></pre><h3>testit [ options ]</h3><p>Exécute une exploration test, qui n&rsquo;explore que l&rsquo;adresse URL de départ et affiche les adresses URL en file d&rsquo;attente.<br/>Si l&rsquo;adresse URL de départ génère un contenu indexable (par exemple, un document), ce<br/>contenu est envoyé à l&rsquo;adaptateur de sortie et le contenu est imprimé à l&rsquo;écran. Si<br/>l&rsquo;extraction de l&rsquo;adresse URL de départ entraîne la mise en file d&rsquo;attente d&rsquo;adresses<br/>URL, ces adresses URL seront affichées et aucun contenu ne sera envoyé à l&rsquo;adaptateur de<br/>sortie. Par défaut, cinq adresses URL en file d&rsquo;attente sont affichées.</p>
<pre><code>-c &lt;valeur&gt; | --config &lt;valeur&gt;  # Indique le fichier de configuration à utiliser. Le fichier par défaut est &quot;config/crawler.conf&quot;.
-l &lt;n&gt; | --limit &lt;n&gt;           # Limite le nombre d&#39;adresses URL en file d&#39;attente affichées.
--pii-checking &lt;valeur&gt;         # Active/Désactive la vérification du PII
</code></pre><h3>restart [ options ]</h3><p>Exécute un redémarrage de l&rsquo;exploration ; lance une nouvelle exploration avec la configuration en cours. </p>
<pre><code>-c &lt;valeur&gt; | --config &lt;valeur&gt;  # Indique le fichier de configuration à utiliser.
</code></pre><p>&ndash;pii-checking <valeur> # Active/Désactive la vérification du PII</p><h3>resume [ options ]</h3><p>Reprend une exploration là où elle s&rsquo;est arrêtée. </p>
<pre><code>-c &lt;valeur&gt; | --config &lt;valeur&gt;  # Indique le fichier de configuration à utiliser.
</code></pre><p>&ndash;pii-checking <valeur> # Active/Désactive la vérification du PII</p><h3>refresh [ options ]</h3><p>Actualise une exploration précédente. </p>
<pre><code>-c &lt;valeur&gt; | --config &lt;valeur&gt;  # Indique le fichier de configuration à utiliser.
</code></pre><p>&ndash;pii-checking <valeur> # Active/Désactive la vérification du PII</p><h3>summary [ options ]</h3><p>Génère un rapport d&rsquo;exploration.</p>
<pre><code>--submitted                    # Interroge tous les documents soumis
--processed                    # N&#39;interroge que les documents correctement traités
--failed                       # N&#39;interroge que les documents dont le traitement à achouer
--group-id &lt;valeur&gt;            # Interroge l&#39;exécution de l&#39;exploration pour un groupe spécifié. Un groupe se compose d&#39;une exploration initiale et de toute reprise, actualisation ou redémarrage de cette exploration initiale. Si la valeur n&#39;est pas spécifiée, cette requête renvoie par défaut le dernier groupe exploré.
--show-content                 # Affiche tout contenu supplémentaire associé à une requête
--filter                       # Filtre le résultat de la requête sur l&#39;adresse URL et l&#39;ID hachage
</code></pre><h2>EXEMPLES</h2><p>Exécutez une exploration à l&rsquo;aide du fichier de configuration qui se trouve dans <code>config/crawler.conf</code> :</p>
<pre><code>crawler crawl
</code></pre><p>Exécutez un test à l&rsquo;aide du fichier de configuration qui se trouve dans <code>config/crawler.conf</code> :</p>
<pre><code>crawler testit
</code></pre><p>Exécutez une exploration à l&rsquo;aide du fichier de configuration qui se trouve dans <code>/home/watson/office-share.conf</code> :</p>
<pre><code>crawler crawl --config /home/watson/office-share.conf
</code></pre><p>Redémarrez une exploration à l&rsquo;aide du fichier de configuration qui se trouve dans <code>/home/watson/office-share.conf</code> :</p>
<pre><code>crawler restart --config /home/watson/office-share.conf
</code></pre><p>Extrayez les informations récapitulatives des documents ayant échoué dont l&rsquo;ID groupe est <code>2</code> :</p>
<pre><code>crawler summary --failed --group-id 2 --show-content
</code></pre><p>Affichez la syntaxe, avec la version :</p>
<pre><code>crawler --help
</code></pre><h2>CONFIGURATION</h2><p><code>crawler</code> requiert un fichier de configuration pour ses options. Des exemples de fichier de configuration sont fournis dans le répertoire <code>share</code> du répertoire d&rsquo;installation du <code>moteur d&#39;exploration</code>. Copiez ces exemples et modifiez-les. <em>Ne modifiez pas les exemples dans leur emplacement.</em></p><p>Si l&rsquo;option <code>--config | -c</code> n&rsquo;est pas spécifiée, le <code>moteur d&#39;exploration</code> recherche son fichier de configuration dans le répertoire <code>config</code> du<br/>répertoire de démarrage du <code>moteur d&#39;exploration</code>. Le <code>moteur d&#39;exploration</code> recherche donc le fichier <code>config/crawler.conf</code>.</p><h2>DIAGNOSTICS</h2><p>Utilisez ces fonctions pour diagnostiquer les problèmes.</p><h3>Débogage</h3><p>Active le mode débogage. Dans le fichier <code>crawler.conf</code>, spécifiez :</p>
<pre><code>debugging.full_node_debugging = true
</code></pre><h3>Consignation</h3><p>Active la consignation. Dans le fichier <code>log4j_custom.properties</code>, spécifiez :</p>
<pre><code>log4j.rootLogger=INFO, Console, Log
</code></pre><p>Il s&rsquo;agit du niveau de consignation par défaut de la sortie du fichier. Pour le journal de la console, la valeur par défaut est la suivante : </p>
<pre><code>log4j.appender.Console.Threshold=WARN
</code></pre><p>Les niveaux de consignation peuvent être définis sur les valeurs suivantes : </p>
<pre><code>OFF - Rang le plus élevé possible ; destiné à désactiver la consignation.
FATAL - Désigne les événements d&#39;erreur très grave qui entraîneront vraisemblablement l&#39;abandon de l&#39;application.
ERROR - Désigne les événements d&#39;erreur qui risquent toutefois de permettre à l&#39;application de poursuivre son exécution.
WARN - Désigne les situations potentiellement dangereuses.
INFO - Désigne les messages d&#39;information indiquant la progression de l&#39;application à un niveau à à granularité grossière.
DEBUG - Désigne les événements d&#39;information à granularité fine les plus utiles pour déboguer une application.
TRACE - Désigne les événements d&#39;information à granularité plus fine que DEBUG.
ALL - Rang le plus faible possible ; destiné à activer la consignation dans son intégralité. 
</code></pre><h2>REGULATION</h2><p>Définit les évaluations en matière de dimensionnement pour faciliter la gestion du débit. Dans le fichier <code>crawler.conf</code>, spécifiez :</p><p><code>shutdown_timeout</code> : indique la valeur du délai d&rsquo;attente, en minutes, avant l&rsquo;arrêt de l&rsquo;application ; la valeur par défaut est de 10.</p>
<pre><code>shutdown_timeout = &lt;n&gt;
</code></pre><p><code>output_limit</code> représente le nombre le plus élevé d&rsquo;éléments indexables que le moteur d&rsquo;exploration portable enverra simultanément<br/>à l&rsquo;adaptateur de sortie, dans l&rsquo;attente d&rsquo;un retour ; la valeur par défaut est de 10. Cette valeur peut être inférieure en fonction des coeurs disponibles pour effectuer le travail.</p>
<pre><code>output_limit = &lt;n&gt;
</code></pre><p><code>input_limit</code> : limite le nombre d&rsquo;adresses URL qui peuvent être demandées simultanément au connecteur ; la valeur par défaut est de 3.</p>
<pre><code>input_limit = &lt;n&gt;
</code></pre><p><code>output_timeout</code> représente la durée, en secondes, avant que le moteur d&rsquo;exploration n&rsquo;abandonne une demande à l&rsquo;adaptateur de sortie, puis supprime<br/>l&rsquo;élément de la file d&rsquo;attente des limites, pour autoriser d&rsquo;autres traitements. La valeur par défaut est de 150.</p>
<pre><code>output_timeout = &lt;n&gt;
</code></pre><p>Vous devez prendre en compte les contraintes imposées par l&rsquo;adaptateur de sortie<br/>car ces contraintes peuvent être liées aux limites définies ici. La valeur<br/><code>output_limit</code> définie ci-dessus ne s&rsquo;intéresse qu&rsquo;à la manière dont de<br/>nombreux objets indexables peuvent être envoyés simultanément à l&rsquo;adaptateur de sortie.<br/>Une fois qu&rsquo;un objet indexable a été envoyé à l&rsquo;adaptateur de sortie, il est &ldquo;pointé&rdquo;, comme défini par la<br/>variable <code>output_timeout</code>. Il est possible que l&rsquo;adaptateur de sortie dispose lui-même d&rsquo;un régulateur l&rsquo;empêchant de pouvoir traiter<br/>autant d&rsquo;entrées qu&rsquo;il n&rsquo;en reçoit. Par exemple, l&rsquo;adaptateur de sortie d&rsquo;orchestration peut comporter un pool de connexions,<br/>configurable pour les connexions HTTP au service. Si sa valeur par défaut est de 8, par exemple, et que vous affectez à<br/><code>output_limit</code> un nombre supérieur à celui configuré pour ce pool de connexions, des processus seront en attente d&rsquo;exécution. Des délais d&rsquo;attente sont alors à prévoir. </p><p><code>num_threads</code> : nombre d&rsquo;unités d&rsquo;exécution en parallèle qui peuvent être exécutées simultanément. Cette valeur peut être un entier,<br/>qui indique directement le nombre d&rsquo;unités d&rsquo;exécution en parallèle, ou une chaîne, au format <code>&quot;xNUM&quot;</code>, qui indique le coefficient multiplicateur du nombre<br/>de processeurs disponibles. La valeur par défaut est &ldquo;x1.5&rdquo;, soit 1,5 fois le nombre de processeurs disponibles (extrait de <code>Runtime.availableProcessors</code>).</p>
<pre><code>num_threads = &lt;n&gt;
</code></pre><p>La formule de calcul du parallélisme dans le pool Data Crawler est la suivante : <code>min(maxThreads, max(minThreads, numThreads))</code>.</p><h2>VARIABLE D&rsquo;ENVIRONNEMENT <code>CRAWLER_OPTS</code></h2><p>Vous trouverez ci-après les propriétés pouvant être transmises au <code>moteur d&#39;exploration</code> via la variable d&rsquo;environnement <code>CRAWLER_OPTS</code>, répertoriées avec les valeurs par défaut. </p><p>Transmettez-les comme suit : </p>
<pre><code>CRAWLER_OPTS=&quot;-Dproperty=valeur -Dproperty=valeur&quot; crawler
</code></pre><p>Ces propriétés ne doivent être modifiées que pour le débogage et uniquement sur demande du support IBM. </p><h3>cfa.java_bin</h3><p><code>cfa.java_bin</code> peut changer la commande <code>java</code> permettant de lancer l&rsquo;adaptateur d&rsquo;entrée de la structure de connecteur. Par défaut, le <code>moteur d&#39;exploration</code> utilise<br/>le même binaire <code>java</code> que celui utilisé pour lancer le <code>moteur d&#39;exploration</code> lui-même.</p><p>Cela peut également être modifié en définissant la propriété<br/><code>java.home</code>, qui sera ensuite utilisée pour déterminer le chemin d&rsquo;accès<br/>à l&rsquo;exécutable <code>java</code>.</p><h3>cfa.lib_dir</h3><p><code>cfa.lib_dir</code> modifie le chemin d&rsquo;accès au répertoire <code>lib</code> de la structure de connecteur. Il est rarement nécessaire de modifier cette propriété. Par défaut,<br/>le <code>moteur d&#39;exploration</code> utilise le répertoire <code>lib</code> à l&rsquo;intérieur du chemin à la structure de connecteur calculé (généralement, simplement <code>connectorFramework</code>).</p><h3>cfa.framework_jars_dir</h3><p><code>cfa.framework_jars_dir</code> modifie le chemin d&rsquo;accès au répertoire jars de la structure de connecteur, qui se trouve par défaut dans <code>connectorFramework/&lt;version&gt;/lib/java</code>.</p><h3>cfa.plugins_dir</h3><p><code>cfa.plugins_dir</code> spécifie le chemin d&rsquo;accès au répertoire des plug-in de la structure de connecteur, où les véritables connecteurs sont stockés.<br/>Par défaut, il est généré à partir de <code>framework_jars_dir</code> et correspond à <code>connectorFramework/&lt;version&gt;/lib/java/plugins</code>.</p><h2>LIMITATIONS CONNUES</h2><p>Détaille les limitations connues dans la version actuelle de Data Crawler</p>
<ul>
  <li>Data Crawler peut se bloquer lors de l&rsquo;exécution du connecteur de système de fichiers avec une adresse URL non valide ou manquante.</li>
  <li>Configurez la valeur <code>urls_to_filter</code> dans le fichier<br/><code>config/crawler.conf</code> de sorte que toutes les adresses URL ou les expressions régulières de la liste<br/>blanche soient incluses dans une même expression régulière.</li>
  <li>Le chemin d&rsquo;accès au fichier de configuration transmis dans l&rsquo;option <code>--config | -c</code> doit être un chemin complet,<br/>à savoir, au format de chemin d&rsquo;accès relatif <code>config/crawler.conf</code> ou<br/><code>./crawler.conf</code> ou au format de chemin d&rsquo;accès absolu <code>/path/to/config/crawler.conf</code>.<br/>Il n&rsquo;est possible de spécifier que <code>crawler.conf</code> si et seulement si les fichiers référencés<br/>à l&rsquo;aide de la fonction <code>include</code> dans le fichier <code>crawler.conf</code> sont incorporés<br/>au lieu d&rsquo;utiliser <code>include</code>. Par exemple,<br/><code>discovery/discovery_service.conf</code> est inclus (à l&rsquo;aide de la fonction<br/><code>include</code>) pour faciliter la lecture de la configuration. Son contenu<br/>doit être copié dans <code>crawler.conf</code>, à l&rsquo;intérieur de la clé<br/><code>output_adapter.discovery_service</code>, pour utiliser un chemin d&rsquo;accès non complet dans l&rsquo;option de configuration.</li>
</ul><h2>JOURNAL DES MODIFICATIONS</h2><p>Pour une liste des modifications apportées dans cette version, consultez le fichier <code>changelog.txt</code> dans votre répertoire d&rsquo;installation. </p><h2>AUTEUR</h2><p>IBM Watson - <a href="https://www.ibm.com/smarterplanet/us/en/ibmwatson/">https://www.ibm.com/smarterplanet/us/en/ibmwatson/</a></p><p>Ecrit par yinz à Pittsburgh.</p><h2>VOIR AUSSI</h2><p>vcrypt(1)</p><p>crawler.conf(5)</p><p>crawler-options.conf(5)</p><p>crawler-seed.conf(5)</p><p>orchestration_service.conf(5)</p>